---
############################################
######### Kafka topics & schemas ###########
- name: "Delete Kafka topics"
  include: toolbox_exec.yml
  vars:
    toolbox_ignore_err: true
    toolbox_debug: "{{ debug_mode }}"
    bash_one_liner: >-
      export JAVA_HOME=/usr/lib/jvm/zulu-8-amd64;
      kafka-topics
      --zookeeper {{ groups['cp_zookeeper_nodes'][0] }}:2181
      --delete
      --topic {{ item.name }}
  loop: "{{ topics | flatten(levels=1) }}"
  when:  pristine_system or absent_from_system

- name: "Create Kafka topics"
  include: toolbox_exec.yml
  vars:
    toolbox_ignore_err: false
    toolbox_debug: "{{ debug_mode }}"
    bash_one_liner: >-
      export JAVA_HOME=/usr/lib/jvm/zulu-8-amd64;
      kafka-topics
      --zookeeper {{ groups['cp_zookeeper_nodes'][0] }}:2181
      --create
      --if-not-exists
      --topic {{ item.name }}
      --partitions {{ item.partitions }}
      --replication-factor {{ item.replication_factor }}

      kafka-topics
      --zookeeper {{ groups['cp_zookeeper_nodes'][0] }}:2181
      --alter
      --topic {{ item.name }}
      {% for config in lookup('dict', item.config)  %}
      --config {{ config.key }}={{ config.value }}
      {% endfor %}
  loop: "{{ topics | flatten(levels=1) }}"
  when: kafka_topics_setup and (not absent_from_system)

- name: "Delete Kafka topics schema"
  uri:
    url: "http://{{ groups['cp_schema_registry'][0] }}:18081/subjects/{{ item.name }}-value"
    method: DELETE
  loop: "{{ topics | flatten(levels=1) }}"
  ignore_errors: true
  when: pristine_system or absent_from_system

- name: "Publish Kafka topics schema"
  uri:
    url: "http://{{ groups['cp_schema_registry'][0] }}:18081/subjects/{{ item.name }}-value/versions"
    headers:
      Content-Type: "application/vnd.schemaregistry.v1+json"
    method: POST
    body_format: json
    body: >-
      {"schema": "{{ lookup("file",  avro_schema_folder + "/" + item.avro.value_schema_file) |  regex_replace('\n| |\t', '') | regex_replace('"', '\"') }}"}
  loop: "{{ topics | flatten(levels=1) }}"
  when:  kafka_topics_setup and (not absent_from_system)


#############################################
########### Flink session & job #############
## https://ci.apache.org/projects/flink/flink-docs-stable/ops/deployment/yarn_setup.html
## TODO: check how to auto restart when yarn recovers (nodes online)
## STOP FLINK's YARN SESSION:
## > echo "stop" | ./bin/yarn-session.sh -id "$(yarn application -list | grep flink-session-daemon | awk '{ print $1}')"
- name: "Flink detached session running"
  include: toolbox_exec.yml
  vars:
    toolbox_ignore_err: true
    toolbox_debug: true
    bash_one_liner: >-
      YARN_APPLICATION_FLINK_SESSION=$(yarn application -list | grep {{ flink_session_yarn_application_name }});
      [[ -z "${YARN_APPLICATION_FLINK_SESSION}" ]] &&
      yarn-session.sh
      -nm "{{ flink_session_yarn_application_name }}"
      -jm {{ flink.job_manager.memory }}
      -n  {{ flink.task_manager.node_count }}
      -s  {{ flink.task_manager.slots }}
      -tm {{ flink.task_manager.memory }}
      -st -d
      || true;
      YARN_APPLICATION_FLINK_SESSION=$(yarn application -list | grep {{ flink_session_yarn_application_name }});
      source /tmp/.yarn-properties-root;
      echo -e "\n\n\n";
      echo -e "Last Flink detached session YARN application id: ${applicationID}";
      echo -e "Flink admin UI: $(echo ${YARN_APPLICATION_FLINK_SESSION} | cut -d " " -f10)";

- name: "Build Flink job as artifact"
  delegate_to: 127.0.0.1
  shell: >-
    cd "{{ sensor_digestion_flink_path }}" &&
    sbt "set test in assembly := {}" clean assembly
  when: build_digestion_project

- name: "Copy Flink job artifact to panda-toolbox"
  become: yes
  copy:
    src: "{{ sensor_digestion_flink_path }}/target/scala-2.11/sensor-digestion-flink-assembly-0.1-SNAPSHOT.jar"
    dest: "{{ toolbox.host.folders.state }}/sensor-digestion-flink-assembly.jar"
    owner: "{{ cluster_config_user }}"
    group: "{{ cluster_config_user }}"
    mode: "u=rx,g=rx"
  when: build_digestion_project

## TODO: Stop job if already started
##    See : https://ci.apache.org/projects/flink/flink-docs-stable/ops/cli.html#job-management-examples
- name: "Flink job running"
  include: toolbox_exec.yml
  vars:
    toolbox_ignore_err: true
    toolbox_debug: "{{ debug_mode }}"
    bash_one_liner: >-
      cd ${TOOLBOX_STATE};
      flink run sensor-digestion-flink-assembly.jar;
  when: true

- meta: end_play

#############################################
########### Kafka connect DB sinks ##########
#
#- name: "Cassandra tables defined"
#  include: cassandra_manage.yml # use toolbox instead....
#  vars:
#    command_args: ./cqlsh -e "lookup('template', 'hosts')"
#
#- name: "Kafka connectors configured"
#
#- name: "Kafka connectors running"
